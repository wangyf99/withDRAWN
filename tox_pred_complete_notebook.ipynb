{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b619d9a",
   "metadata": {},
   "source": [
    "# Toxicity Prediction Ensemble Notebook\n",
    "This notebook reproduces the full functionality of `tox_pred.py`.\n",
    "It loads drug feature datasets, trains base models, and builds an ensemble classifier to predict drug withdrawal risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad716a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba36bd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     accuracy_score, roc_auc_score, f1_score,\n\u001b[1;32m      8\u001b[0m     precision_score, recall_score, matthews_corrcoef\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VarianceThreshold, GenericUnivariateSelect, chi2\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtpot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TPOTClassifier\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tpot/__init__.py:27\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"This file is part of the TPOT library.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mTPOT was primarily developed at the University of Pennsylvania by:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TPOTClassifier, TPOTRegressor\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tpot/tpot.py:26\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"This file is part of the TPOT library.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mTPOT was primarily developed at the University of Pennsylvania by:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TPOTBase\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier_config_dict\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregressor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regressor_config_dict\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tpot/base.py:64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_pipeline, expr_to_tree, generate_pipeline_code, set_param_recursive\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pre_test\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CombineDFs, StackingEstimator\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier_light\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classifier_config_dict_light\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregressor_light\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regressor_config_dict_light\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tpot/builtins/__init__.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine_dfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CombineDFs\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstacking_estimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StackingEstimator\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mone_hot_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder, auto_select_categorical_features, _transform_selected\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalSelector, ContinuousSelector\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_set_selector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureSetSelector\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tpot/builtins/one_hot_encoder.py:136\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack((X_sel, X_not_sel))\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOneHotEncoder\u001b[39;00m(BaseEstimator, TransformerMixin):\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Encode categorical integer features using a one-hot aka one-of-K scheme.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    The input to this transformer should be a matrix of integers, denoting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m      encoding of dictionary items or strings.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, categorical_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat,\n\u001b[1;32m    217\u001b[0m                  sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, minimum_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tpot/builtins/one_hot_encoder.py:216\u001b[0m, in \u001b[0;36mOneHotEncoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOneHotEncoder\u001b[39;00m(BaseEstimator, TransformerMixin):\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Encode categorical integer features using a one-hot aka one-of-K scheme.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    The input to this transformer should be a matrix of integers, denoting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m      encoding of dictionary items or strings.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, categorical_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat,\n\u001b[1;32m    217\u001b[0m                  sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, minimum_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_features \u001b[38;5;241m=\u001b[39m categorical_features\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob, math, random, statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score,\n",
    "    precision_score, recall_score, matthews_corrcoef\n",
    ")\n",
    "from sklearn.feature_selection import VarianceThreshold, GenericUnivariateSelect, chi2\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('tox_labels.csv')\n",
    "drug_features = pd.read_csv('drug_features.csv')\n",
    "fp = pd.read_csv('fp.csv')\n",
    "targets = pd.read_csv('targetsall.csv')\n",
    "sages = pd.read_csv('sages.csv')\n",
    "print('Datasets loaded successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(features, labels, label_col=None, test_size=0.3, random_state=42):\n",
    "    if label_col is None:\n",
    "        label_col = labels.columns[-1]\n",
    "    y = labels[label_col]\n",
    "    X = features.copy()\n",
    "    if 'Drug_ID' in X.columns:\n",
    "        X = X.drop(columns=['Drug_ID'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def select_features(X_train, X_test, threshold=0.1):\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    X_train_sel = selector.fit_transform(X_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    return X_train_sel, X_test_sel\n",
    "\n",
    "def train_rf(X_train, X_test, y_train, y_test, model_id):\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_train = rf.predict_proba(X_train)[:,1]\n",
    "    pred_test = rf.predict_proba(X_test)[:,1]\n",
    "    os.makedirs('ensemble_train_603010', exist_ok=True)\n",
    "    pd.DataFrame(pred_train, columns=['pred']).to_csv(f'ensemble_train_603010/{model_id}-level2_train.csv', index=False)\n",
    "    pd.DataFrame(pred_test, columns=['pred']).to_csv(f'ensemble_train_603010/{model_id}-level2_test.csv', index=False)\n",
    "    print(f'Model {model_id} trained and saved.')\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b22fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [drug_features, fp, targets, sages]\n",
    "names = ['Chemical', 'Fingerprint', 'Targets', 'SAGES']\n",
    "models = []\n",
    "for i, (data, name) in enumerate(zip(datasets, names)):\n",
    "    print(f'\\nTraining base model for {name} features...')\n",
    "    X_train, X_test, y_train, y_test = prepare_data(data, labels)\n",
    "    X_train_sel, X_test_sel = select_features(X_train, X_test)\n",
    "    model = train_rf(X_train_sel, X_test_sel, y_train, y_test, i)\n",
    "    models.append(model)\n",
    "print('All base models trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted(glob.glob('ensemble_train_603010/*train.csv'))\n",
    "test_files = sorted(glob.glob('ensemble_train_603010/*test.csv'))\n",
    "X_train_ens = np.column_stack([pd.read_csv(f)['pred'].values for f in train_files])\n",
    "X_test_ens = np.column_stack([pd.read_csv(f)['pred'].values for f in test_files])\n",
    "y_train = labels.iloc[:X_train_ens.shape[0], -1]\n",
    "y_test = labels.iloc[y_train.shape[0]:y_train.shape[0]+X_test_ens.shape[0], -1]\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train_ens, y_train)\n",
    "ensemble_preds = tpot.predict(X_test_ens)\n",
    "print('\\n=== Ensemble Evaluation ===')\n",
    "print('Accuracy:', accuracy_score(y_test, ensemble_preds))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, ensemble_preds))\n",
    "print('F1:', f1_score(y_test, ensemble_preds))\n",
    "print('Precision:', precision_score(y_test, ensemble_preds))\n",
    "print('Recall:', recall_score(y_test, ensemble_preds))\n",
    "print('MCC:', matthews_corrcoef(y_test, ensemble_preds))\n",
    "tpot.export('best_ensemble_pipeline.py')\n",
    "print('Best ensemble pipeline exported.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
